# CARBS

**CARBS** (short for *Cost-Aware Randomized Benchmark Search*) is a hyperparameter tuning framework tailored for reinforcement learning workloads. It focuses on efficient exploration of hyperparameter spaces by considering both performance and computational cost, making it well-suited for expensive and stochastic training tasks in RL.

---

## ğŸ” Overview

- Designed for **automated hyperparameter optimization** in reinforcement learning.  
- Emphasizes **cost-awareness**, balancing training performance with computation time.  
- Developed to outperform naive grid or random search in noisy, expensive RL settings.  
- Works well for tuning PPO, SAC, DQN, and other algorithms with many sensitive parameters.

---

## ğŸ§  Core Concepts

- **Multi-Fidelity Optimization**: Uses partial training runs to estimate final performance.  
- **Cost-Aware Sampling**: Prefers configurations that are both performant and efficient.  
- **Bandit-Based Strategy**: Inspired by successive halving and Hyperband-like methods.  
- **Stochasticity-Resilience**: Can cope with noisy performance metrics from RL environments.  
- **Meta-Optimization**: Automates what would otherwise be manual trial-and-error.

---

## ğŸ§° Use Cases

- Tuning PPO's learning rate, GAE lambda, entropy coefficient, and clip range.  
- Adjusting replay buffer size, batch size, and target network updates for DQN or SAC.  
- Running low-budget optimization for experiments on limited hardware.  
- Efficient sweeping of environments with high variance in rewards (e.g., [[Puffer Environments]]).

---

## âœ… Pros

- Avoids full-length training for each config, saving compute.  
- Handles noisy metrics better than standard Bayesian optimizers.  
- Adapts budget usage based on cost-performance trade-offs.  
- Strong performance on real RL workloads from benchmark suites like MuJoCo and Atari.

---

## âŒ Cons

- Less widely adopted than popular tools like Optuna or Ray Tune.  
- Requires deeper integration with RL training scripts than basic grid search.  
- May need tuning of its own meta-hyperparameters for best results.

---

## ğŸ“Š Comparison Table: CARBS vs Other HPO Methods

| Method           | Handles RL Stochasticity | Budget-Aware | Multi-Fidelity | Popular Use in RL |
|------------------|--------------------------|--------------|----------------|--------------------|
| CARBS            | âœ… Yes                   | âœ… Yes       | âœ… Yes         | ğŸŸ¡ Growing         |
| [[Grid Search]]  | âŒ No                    | âŒ No        | âŒ No          | âœ… Common          |
| [[Random Search]]| âŒ No                    | âŒ No        | âŒ No          | âœ… Common          |
| Bayesian Opt     | ğŸŸ¡ Sometimes             | ğŸŸ¡ Partial   | ğŸŸ¡ Optional    | âœ… Popular         |
| [[Hyperband]]    | âœ… Yes                   | âœ… Yes       | âœ… Yes         | âœ… Common          |

---

## ğŸ”§ Compatible Items

- [[PPO]] â€“ Policy Gradient method with sensitive hyperparameters  
- [[SAC]] â€“ Off-policy method requiring tuning of alpha, tau, buffer size, etc.  
- [[Replay Buffer]] â€“ Parameters such as size and sample strategy can be tuned  
- [[GAE]] â€“ Tuning lambda impacts performance/stability  
- [[Batch Processing]] â€“ Related to batch size and update frequency

---

## ğŸ”— Related Concepts

- [[Hyperparameter Optimization]] â€“ General category CARBS belongs to  
- [[RL Training Pipelines]] â€“ Where CARBS is integrated  
- [[On-Policy]] / [[Off-Policy]] â€“ CARBS can optimize both types  
- [[RL Algorithm Configuration]] â€“ What CARBS automates  
- [[RL Reward Signal]] â€“ The objective CARBS helps maximize

---

## ğŸ“š Further Reading

- [CARBS GitHub Repository](https://github.com/facebookresearch/CARBS)  
- [Facebook Research Blog on CARBS](https://ai.facebook.com/research/publications/cost-aware-randomized-benchmark-search-for-hyperparameter-optimization/)  
- [Paper: Cost-Aware Randomized Benchmark Search](https://arxiv.org/abs/2111.09179)  
- [Hyperparameter Tuning in RL â€“ Survey](https://arxiv.org/abs/2007.03966)  

---
