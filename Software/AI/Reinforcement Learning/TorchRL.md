# TorchRL

**TorchRL** is a PyTorch-native reinforcement learning (RL) library developed by Meta AI. It provides modular, high-performance components for building, training, and evaluating RL agents. Its deep integration with PyTorch makes it a powerful tool for researchers and practitioners looking to prototype or scale RL algorithms using familiar APIs.

---

## üîç Overview

- Built directly on top of PyTorch and [[TorchScript]] for efficient deployment.  
- Offers modular primitives for environments, data collection, replay buffers, policies, losses, transforms, and training loops.  
- Supports both on-policy and off-policy algorithms like [[PPO]], [[DQN]], [[SAC]], and [[TD Learning]].  
- Compatible with [[Gym]], [[DMControl]], [[Isaac Gym]], and [[EnvPool]] environments.  
- Easily integrates with [[TorchRL EnvWrappers]], [[Replay Buffers]], and distributed setups.

---

## üß† Core Concepts

- **Transform Pipelines**: Preprocessing pipelines for observations and rewards.  
- **TensorDict**: TorchRL‚Äôs core data structure for managing batched data.  
- **Replay Buffers**: Built-in support for prioritized and multi-step buffers.  
- **RLModules**: Modular actor-critic components for building custom policies.  
- **Loss Modules**: Plug-and-play implementation of common loss functions.  
- **Collector Classes**: Tools for managing on-policy/off-policy rollout strategies.  

---

## üß∞ Use Cases

- Prototyping novel RL algorithms with PyTorch-level flexibility.  
- Reproducible baseline training and benchmarking.  
- High-performance distributed training when paired with tools like [[moolib]] or TorchRL‚Äôs own launchers.  
- Academic and industrial research requiring low-level control with high-level structure.

---

## ‚úÖ Pros

- Seamlessly integrates with PyTorch ecosystem.  
- Modular and extensible ‚Äì components can be swapped in/out easily.  
- Accelerated by TorchScript and [[torch.compile]] for deployment or speed.  
- Rich environment support including vectorized and GPU-accelerated sim backends.  

---

## ‚ùå Cons

- Newer library, so some bugs and limitations in less-used features.  
- Smaller community compared to SB3 or RLlib.  
- May require a deeper PyTorch understanding for advanced customization.  

---

## üìä Comparison Table: TorchRL vs Other RL Libraries

| Feature              | TorchRL           | [[Stable-Baselines3]]   | [[Ray RLlib]]            | [[moolib]]                |
|----------------------|-------------------|----------------------|-----------------------|------------------------|
| Language             | Python (PyTorch)  | Python (PyTorch)     | Python                | Python + C++           |
| Distribution Support | üü° Partial         | ‚ùå Minimal            | ‚úÖ Strong             | ‚úÖ Strong              |
| Extensibility        | ‚úÖ High            | üü° Medium             | üü° Medium             | ‚úÖ High               |
| Built-in Algorithms  | ‚úÖ PPO, SAC, DQN   | ‚úÖ PPO, A2C, DDPG     | ‚úÖ Wide Range         | ‚ùå BYO Algorithms      |
| Envs Supported       | Gym, DMControl, EnvPool, Isaac Gym | Gym  | Gym, PettingZoo      | Gym                    |

---

## üîß Compatible Items

- [[PyTorch]] ‚Äì Core foundation  
- [[EnvPool]], [[Isaac Gym]], [[Gym]] ‚Äì TorchRL supports them all  
- [[Replay Buffer]] ‚Äì Natively implemented with multiple variants  
- [[TensorDict]] ‚Äì TorchRL‚Äôs container for batched data  
- [[Policy Gradient Methods]] ‚Äì Directly supported  
- [[CARBS]] ‚Äì For hyperparameter tuning of TorchRL agents  
- [[PufferLib]] ‚Äì Can wrap TorchRL environments and agents  

---

## üîó Related Concepts

- [[Reinforcement Learning]] ‚Äì TorchRL provides core infrastructure  
- [[RL Agent]], [[RL Environment]], [[RL Policy]], [[RL Trajectory]]  
- [[On-Policy]] and [[Off-Policy]] algorithms  
- [[Stable-Baselines3]] ‚Äì Simpler alternative for smaller projects  
- [[moolib]] ‚Äì Can be paired for distributed rollout + TorchRL training

---

## üìö Further Reading

- [TorchRL GitHub Repository](https://github.com/pytorch/rl)  
- [TorchRL Documentation](https://pytorch.org/rl)  
- [TorchRL Blog Launch Post by Meta AI](https://ai.facebook.com/blog/introducing-torchrl-a-library-for-reinforcement-learning-in-pytorch/)  
- [TorchRL Tutorials and Notebooks](https://pytorch.org/rl/tutorials/)  

---
